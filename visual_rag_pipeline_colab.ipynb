{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8179641",
   "metadata": {},
   "source": [
    "# Visual RAG Pipeline (Colab Version)\n",
    "\n",
    "**Project:** Visual RAG for German Portfolio Evaluation\n",
    "\n",
    "## Overview\n",
    "This notebook implements a **Visual Retrieval-Augmented Generation (RAG)** pipeline for evaluating German student portfolios. This system treats PDF pages as **images** to preserve spatial context (charts, tables, layouts).\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "PDF Document ‚Üí ColPali (Visual Retrieval) ‚Üí Top-K Pages ‚Üí Llama Vision (Groq API) ‚Üí Answer\n",
    "```\n",
    "\n",
    "## Components\n",
    "| Component | Model | Purpose |\n",
    "|-----------|-------|---------|\n",
    "| Retriever | vidore/colpali-v1.3 | Visual document retrieval with MaxSim scoring |\n",
    "| Generator | Llama 4 Scout (Groq) | Multimodal answer generation via API |\n",
    "\n",
    "## Methodology\n",
    "1. **Ingest:** Convert PDF pages into screenshots\n",
    "2. **Index:** Create visual embeddings using ColPali\n",
    "3. **Retrieve:** Find the most relevant page images\n",
    "4. **Generate:** Pass page images + query to Llama Vision via Groq API\n",
    "\n",
    "> **Note:** For local/cluster deployment with Qwen2-VL, see `run_visual_rag.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3377a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è Step 1: Install Dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        \"byaldi==0.0.5\",\n",
    "        \"pdf2image\",\n",
    "        \"openai\",\n",
    "        \"overrides\",\n",
    "        \"ipython\"\n",
    "    ]\n",
    "\n",
    "    subprocess.run([\"sudo\", \"apt-get\", \"install\", \"-y\", \"poppler-utils\"], check=True)\n",
    "\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", package])\n",
    "\n",
    "    print(\"‚úÖ Setup complete. Please RESTART SESSION if this is the first run.\")\n",
    "\n",
    "try:\n",
    "    import byaldi\n",
    "except ImportError:\n",
    "    install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß† Step 2: Define Visual RAG System\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from typing import List, Any\n",
    "from byaldi import RAGMultiModalModel\n",
    "from groq import Groq\n",
    "from IPython.display import Image, display\n",
    "from google.colab import userdata\n",
    "\n",
    "# Configuration\n",
    "RETRIEVER_MODEL = \"vidore/colpali-v1.3\"\n",
    "LLM_MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "INDEX_NAME = \"visual_doc_index\"\n",
    "\n",
    "class MultimodalRAG:\n",
    "    \"\"\"\n",
    "    Implements a Visual RAG pipeline: PDF -> Page Images -> Visual Embeddings -> Retrieval -> VLM Answer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rag_engine = None\n",
    "        self.groq_client = None\n",
    "        self.index_loaded = False\n",
    "\n",
    "    def _load_retriever(self):\n",
    "        \"\"\"Lazy loads the ColPali model to save resources until needed.\"\"\"\n",
    "        if self.rag_engine is None:\n",
    "            print(f\"üîÑ Loading Retriever ({RETRIEVER_MODEL})...\")\n",
    "            self.rag_engine = RAGMultiModalModel.from_pretrained(RETRIEVER_MODEL)\n",
    "\n",
    "    def authenticate(self):\n",
    "        \"\"\"Retrieves 'GROQ_API_KEY' from Colab secrets.\"\"\"\n",
    "        try:\n",
    "            key = userdata.get('GROQ_API_KEY')\n",
    "            if not key or not key.startswith(\"gsk_\"):\n",
    "                raise ValueError(\"Invalid Key format\")\n",
    "            self.groq_client = Groq(api_key=key)\n",
    "            print(\"‚úÖ Authenticated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Authentication Failed: {e}\")\n",
    "\n",
    "    def ingest_pdf(self, pdf_url: str, force_reindex: bool = False):\n",
    "        \"\"\"Downloads PDF and creates visual embeddings for all pages.\"\"\"\n",
    "        self._load_retriever()\n",
    "\n",
    "        index_path = f\".byaldi/{INDEX_NAME}\"\n",
    "        if os.path.exists(index_path) and not force_reindex:\n",
    "            try:\n",
    "                self.rag_engine.load_index(INDEX_NAME)\n",
    "                self.index_loaded = True\n",
    "                print(f\"‚úÖ Loaded existing index: {INDEX_NAME}\")\n",
    "                return\n",
    "            except Exception:\n",
    "                print(\"‚ö†Ô∏è Index corrupted, re-indexing...\")\n",
    "\n",
    "        print(f\"‚¨áÔ∏è Downloading PDF...\")\n",
    "        response = requests.get(pdf_url)\n",
    "        with open(\"input.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(\"üëÄ Indexing document...\")\n",
    "        self.rag_engine.index(\n",
    "            input_path=\"input.pdf\",\n",
    "            index_name=INDEX_NAME,\n",
    "            store_collection_with_index=True,\n",
    "            overwrite=True\n",
    "        )\n",
    "        self.index_loaded = True\n",
    "        print(\"‚úÖ Indexing complete.\")\n",
    "\n",
    "    def search(self, query: str, k: int = 1) -> List[Any]:\n",
    "        \"\"\"Retrieves top-k page results based on visual similarity.\"\"\"\n",
    "        self._load_retriever()\n",
    "        if not self.index_loaded:\n",
    "            # Attempt recovery if index exists but wasn't explicitly loaded\n",
    "            try:\n",
    "                self.rag_engine.load_index(INDEX_NAME)\n",
    "                self.index_loaded = True\n",
    "            except:\n",
    "                raise RuntimeError(\"No index found. Run ingest_pdf() first.\")\n",
    "\n",
    "        return self.rag_engine.search(query, k=k)\n",
    "\n",
    "    def generate_answer(self, query: str, result: Any) -> str:\n",
    "        \"\"\"Generates an answer using Llama Vision based on the retrieved page image.\"\"\"\n",
    "        if not self.groq_client:\n",
    "            raise RuntimeError(\"Client not authenticated.\")\n",
    "\n",
    "        image_data = base64.b64decode(result.base64)\n",
    "        \n",
    "        print(f\"\\nüìÑ Context Found on Page {result.page_num}:\")\n",
    "        display(Image(data=image_data, width=500))\n",
    "\n",
    "        try:\n",
    "            chat_completion = self.groq_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": f\"Context is provided in the image. Question: {query}\"},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{result.base64}\"}},\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                model=LLM_MODEL,\n",
    "                temperature=0.1,  # Low temperature for factual consistency\n",
    "            )\n",
    "            return chat_completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå GenAI Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0b6ca",
   "metadata": {},
   "outputs": [],
   "source": "# @title üöÄ Step 3: Run Pipeline\nrag_system = MultimodalRAG()\nrag_system.authenticate()\n\n# Ingest Target Document\nPDF_URL = \"/Users/ningning/workspace/VisualRagPipeline/doc/handbuch_portfolio.pdf\" \nrag_system.ingest_pdf(PDF_URL)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ü§ñ Visual RAG Assistant Ready. Type 'exit' to quit.\")\nprint(\"=\"*50)\n\nwhile True:\n    user_query = input(\"\\n‚ùì Ask a question: \")\n\n    if user_query.lower() in ['exit', 'quit']:\n        break\n\n    results = rag_system.search(user_query, k=1)\n\n    if results:\n        answer = rag_system.generate_answer(user_query, results[0])\n        print(f\"\\n‚ú® Answer:\\n{answer}\\n\" + \"-\"*50)\n    else:\n        print(\"‚ùå No relevant information found.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}